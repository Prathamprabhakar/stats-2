{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mykOI4KhL7x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "1. What is hypothesis testing in statistics?\n",
        "\n",
        "Hypothesis testing is a statistical method used to make decisions or inferences about a population based on sample data. It involves formulating a null and alternative hypothesis and using data to determine which is more likely.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "Null hypothesis (H₀): A default claim that there is no effect or difference (e.g., \"The mean is equal to X\").\n",
        "\n",
        "Alternative hypothesis (H₁ or Ha): A statement that contradicts the null (e.g., \"The mean is not equal to X\").\n",
        "They are mutually exclusive.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "The significance level (α) is the threshold for rejecting the null hypothesis, commonly set at 0.05. It represents the probability of making a Type I error—rejecting a true null hypothesis.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "\n",
        "The P-value is the probability of obtaining results at least as extreme as those observed, assuming the null hypothesis is true.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "If P-value ≤ α, reject the null hypothesis (evidence supports the alternative).\n",
        "\n",
        "If P-value > α, fail to reject the null hypothesis (insufficient evidence).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "Type I error (α): Rejecting a true null hypothesis.\n",
        "\n",
        "Type II error (β): Failing to reject a false null hypothesis.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "\n",
        "One-tailed test: Tests for effect in one direction (e.g., greater than).\n",
        "\n",
        "Two-tailed test: Tests for effect in both directions (e.g., not equal to).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "\n",
        "A Z-test is used to test hypotheses about population means when the population variance is known and the sample size is large (n > 30).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "\n",
        "Z = (X̄ - μ) / (σ / √n)\n",
        "It shows how many standard deviations a sample mean is from the population mean under the null hypothesis.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "\n",
        "The T-distribution is used when the sample size is small (n < 30) and the population standard deviation is unknown. It is similar to the normal distribution but has heavier tails.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "\n",
        "Z-test: Known population variance and large sample size.\n",
        "\n",
        "T-test: Unknown population variance and small sample size.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "\n",
        "A T-test is used to compare sample means or a sample mean against a known value, especially with small sample sizes or unknown variance.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "\n",
        "Both test means, but a T-test is more general and applicable when population variance is unknown. As sample size increases, the T-distribution approaches the normal distribution, making T-tests converge to Z-tests.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "\n",
        "A confidence interval gives a range of values within which the population parameter likely falls, with a given confidence level (e.g., 95%).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "15. What is the margin of error, and how does it affect the confidence interval?\n",
        "\n",
        "The margin of error is the range added/subtracted from the point estimate to get the confidence interval. Larger margins mean wider intervals, indicating more uncertainty.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "\n",
        "Bayes' Theorem is used to update probabilities based on new evidence. It’s foundational in Bayesian statistics, enabling dynamic inference.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "\n",
        "The Chi-square distribution is used for categorical data analysis, such as tests of independence and goodness-of-fit. It’s skewed right and defined only for non-negative values.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "\n",
        "It tests whether observed categorical data fit a specified distribution. Compares observed and expected frequencies using the Chi-square statistic.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "\n",
        "The F-distribution is used to compare variances or in ANOVA. It arises when testing ratios of variances and is always positive and right-skewed.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "\n",
        "ANOVA (Analysis of Variance) tests whether there are statistically significant differences between three or more group means.\n",
        "Assumptions:\n",
        "\n",
        "Independence\n",
        "\n",
        "Normality\n",
        "\n",
        "Equal variances (homogeneity)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "21. What are the different types of ANOVA tests?\n",
        "\n",
        "One-way ANOVA: One independent variable.\n",
        "\n",
        "Two-way ANOVA: Two independent variables.\n",
        "\n",
        "Repeated measures ANOVA: Repeated observations on the same subjects.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "An F-test is used to compare two variances or test the overall significance in ANOVA. It determines whether group means or variances differ significantly.\n",
        "\n",
        "\n",
        "PRACTICAL\n",
        "\n",
        "1. Generate a Random Variable and Display its Value\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "x = np.random.rand()\n",
        "print(\"Random Variable:\", x)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "2. Discrete Uniform Distribution and Plot PMF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "low, high = 1, 7  # Simulating dice roll (1 to 6)\n",
        "x = np.arange(low, high)\n",
        "pmf = randint.pmf(x, low, high)\n",
        "\n",
        "plt.stem(x, pmf, use_line_collection=True)\n",
        "plt.title(\"PMF of Discrete Uniform Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. Bernoulli Distribution PDF\n",
        "\n",
        "from scipy.stats import bernoulli\n",
        "\n",
        "def bernoulli_pdf(p):\n",
        "    x = [0, 1]\n",
        "    probs = bernoulli.pmf(x, p)\n",
        "    return dict(zip(x, probs))\n",
        "\n",
        "print(bernoulli_pdf(0.6))\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "4. Simulate Binomial Distribution and Plot Histogram\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, p = 10, 0.5\n",
        "samples = np.random.binomial(n, p, 1000)\n",
        "\n",
        "plt.hist(samples, bins=range(n+2), density=True, alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Binomial Distribution Histogram\")\n",
        "plt.xlabel(\"Number of Successes\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "5. Create Poisson Distribution and Visualize\n",
        "\n",
        "from scipy.stats import poisson\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mu = 3\n",
        "x = np.arange(0, 10)\n",
        "pmf = poisson.pmf(x, mu)\n",
        "\n",
        "plt.stem(x, pmf, use_line_collection=True)\n",
        "plt.title(\"Poisson Distribution (μ=3)\")\n",
        "plt.xlabel(\"Number of Events\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "6. CDF of Discrete Uniform Distribution\n",
        "\n",
        "from scipy.stats import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "low, high = 1, 7\n",
        "x = np.arange(low, high)\n",
        "cdf = randint.cdf(x, low, high)\n",
        "\n",
        "plt.step(x, cdf, where='post')\n",
        "plt.title(\"CDF of Discrete Uniform Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Cumulative Probability\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7. Continuous Uniform Distribution and Visualization\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import uniform\n",
        "\n",
        "samples = uniform.rvs(loc=0, scale=1, size=1000)\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Continuous Uniform Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "8. Simulate Normal Distribution and Plot Histogram\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "samples = np.random.normal(loc=0, scale=1, size=1000)\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
        "plt.title(\"Normal Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "9. Calculate Z-scores and Plot\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "\n",
        "data = np.random.normal(10, 2, 100)\n",
        "z_scores = zscore(data)\n",
        "\n",
        "plt.hist(z_scores, bins=30, edgecolor='black')\n",
        "plt.title(\"Z-scores of Dataset\")\n",
        "plt.xlabel(\"Z-score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "10. Central Limit Theorem Simulation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Exponential distribution (non-normal)\n",
        "population = np.random.exponential(scale=2, size=100000)\n",
        "\n",
        "sample_means = []\n",
        "for _ in range(1000):\n",
        "    sample = np.random.choice(population, size=30)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "plt.hist(sample_means, bins=30, density=True, edgecolor='black', alpha=0.7)\n",
        "plt.title(\"CLT: Sample Means from Exponential Distribution\")\n",
        "plt.xlabel(\"Sample Mean\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show\n",
        "\n",
        "\n",
        "\n",
        "11. Simulate Normal Samples and Verify CLT\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "means = []\n",
        "for _ in range(1000):\n",
        "    sample = np.random.normal(loc=50, scale=10, size=30)\n",
        "    means.append(np.mean(sample))\n",
        "\n",
        "plt.hist(means, bins=30, density=True, edgecolor='black')\n",
        "plt.title(\"CLT: Distribution of Sample Means\")\n",
        "plt.xlabel(\"Sample Mean\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "12. Standard Normal Distribution Plot\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal():\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(\"Standard Normal Distribution\")\n",
        "    plt.xlabel(\"Z\")\n",
        "    plt.ylabel(\"PDF\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_standard_normal()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "13. Binomial Probabilities for Random Variables\n",
        "\n",
        "from scipy.stats import binom\n",
        "\n",
        "n, p = 10, 0.5\n",
        "x = np.arange(0, n+1)\n",
        "probabilities = binom.pmf(x, n, p)\n",
        "print(dict(zip(x, probabilities)))\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "14. Z-score for a Data Point\n",
        "\n",
        "def calculate_z_score(x, mu, sigma):\n",
        "    z = (x - mu) / sigma\n",
        "    return z\n",
        "\n",
        "z = calculate_z_score(75, 70, 5)\n",
        "print(\"Z-score:\", z)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "15. Hypothesis Testing using Z-statistic\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Sample\n",
        "data = np.random.normal(loc=100, scale=15, size=30)\n",
        "sample_mean = np.mean(data)\n",
        "pop_mean = 95\n",
        "pop_std = 15\n",
        "n = len(data)\n",
        "\n",
        "z = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "p_value = 1 - norm.cdf(z)\n",
        "\n",
        "print(f\"Z: {z:.2f}, P-value: {p_value:.4f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "16. Confidence Interval from Data\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = np.random.normal(loc=50, scale=5, size=100)\n",
        "mean = np.mean(data)\n",
        "sem = stats.sem(data)\n",
        "ci = stats.t.interval(0.95, len(data)-1, loc=mean, scale=sem)\n",
        "\n",
        "print(\"95% Confidence Interval:\", ci)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "17. CI from Normal Distribution and Interpretation\n",
        "\n",
        "data = np.random.normal(loc=60, scale=10, size=50)\n",
        "mean = np.mean(data)\n",
        "sem = stats.sem(data)\n",
        "ci = stats.t.interval(0.95, df=len(data)-1, loc=mean, scale=sem)\n",
        "\n",
        "print(f\"Sample Mean = {mean:.2f}\")\n",
        "print(f\"95% CI for Mean = {ci}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "18. Normal PDF Visualization\n",
        "\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "pdf = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "plt.plot(x, pdf)\n",
        "plt.title(\"PDF of Normal Distribution\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "19. Poisson CDF Calculation\n",
        "\n",
        "from scipy.stats import poisson\n",
        "\n",
        "mu = 3\n",
        "x = np.arange(0, 10)\n",
        "cdf = poisson.cdf(x, mu)\n",
        "print(dict(zip(x, cdf)))\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "20. Continuous Uniform Random Variable and Expected Value\n",
        "\n",
        "from scipy.stats import uniform\n",
        "\n",
        "a, b = 5, 15\n",
        "sample = uniform.rvs(loc=a, scale=b-a, size=1000)\n",
        "expected_value = np.mean(sample)\n",
        "print(f\"Expected Value (approx): {expected_value:.2f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "21. Compare Standard Deviations and Visualize\n",
        "\n",
        "data1 = np.random.normal(0, 1, 100)\n",
        "data2 = np.random.normal(0, 2, 100)\n",
        "\n",
        "print(\"STD Data1:\", np.std(data1))\n",
        "print(\"STD Data2:\", np.std(data2))\n",
        "\n",
        "plt.hist(data1, alpha=0.5, label='Std=1')\n",
        "plt.hist(data2, alpha=0.5, label='Std=2')\n",
        "plt.legend()\n",
        "plt.title(\"Comparing Standard Deviations\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "22. Calculate Range and IQR\n",
        "\n",
        "data = np.random.normal(100, 15, 100)\n",
        "data_range = np.max(data) - np.min(data)\n",
        "iqr = np.percentile(data, 75) - np.percentile(data, 25)\n",
        "\n",
        "print(\"Range:\", data_range)\n",
        "print(\"IQR:\", iqr)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "23. Z-score Normalization and Visualization\n",
        "\n",
        "data = np.random.normal(50, 10, 100)\n",
        "normalized = zscore(data)\n",
        "\n",
        "plt.hist(normalized, bins=30, edgecolor='black')\n",
        "plt.title(\"Z-score Normalized Data\")\n",
        "plt.xlabel(\"Z-score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "24. Skewness and Kurtosis of Normal Data\n",
        "\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "data = np.random.normal(0, 1, 1000)\n",
        "print(\"Skewness:\", skew(data))\n",
        "print(\"Kurtosis:\", kurtosis(data))\n",
        "\n",
        "\n",
        "\n",
        "PART 2\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "1. Z-test for Sample Mean vs Population Mean\n",
        "\n",
        "from scipy.stats import norm\n",
        "import numpy as np\n",
        "\n",
        "def z_test(sample, pop_mean, pop_std):\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    z = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
        "    p = 2 * (1 - norm.cdf(abs(z)))\n",
        "    print(f\"Z-score = {z:.3f}, P-value = {p:.3f}\")\n",
        "    return z, p\n",
        "\n",
        "data = np.random.normal(100, 15, 30)\n",
        "z_test(data, pop_mean=95, pop_std=15)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "2. Simulate Data and Perform Hypothesis Test\n",
        "\n",
        "sample = np.random.normal(50, 10, 40)\n",
        "z_stat, p_val = z_test(sample, pop_mean=52, pop_std=10)\n",
        "print(f\"Simulated P-value: {p_val:.4f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. One-sample Z-test\n",
        "\n",
        "(Same as #1 — wrapped in a reusable function)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "4. Two-tailed Z-test with Decision Region Plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z_score = 2.0\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.fill_between(x, y, where=(x <= -1.96) | (x >= 1.96), color='red', alpha=0.3, label='Rejection Region')\n",
        "plt.axvline(z_score, color='blue', linestyle='--', label='Z-score')\n",
        "plt.title(\"Two-tailed Z-test\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "5. Visualize Type I and II Errors\n",
        "\n",
        "def plot_type_errors(mu0, mu1, sigma, n, alpha=0.05):\n",
        "    se = sigma / np.sqrt(n)\n",
        "    x = np.linspace(mu0 - 4*se, mu1 + 4*se, 1000)\n",
        "    y0 = norm.pdf(x, mu0, se)\n",
        "    y1 = norm.pdf(x, mu1, se)\n",
        "    \n",
        "    z_critical = norm.ppf(1 - alpha/2)\n",
        "    upper_crit = mu0 + z_critical * se\n",
        "    lower_crit = mu0 - z_critical * se\n",
        "    \n",
        "    plt.plot(x, y0, label='H0', color='blue')\n",
        "    plt.plot(x, y1, label='H1', color='orange')\n",
        "    plt.axvline(upper_crit, color='red', linestyle='--')\n",
        "    plt.axvline(lower_crit, color='red', linestyle='--')\n",
        "    \n",
        "    plt.fill_between(x, y1, where=(x < lower_crit) | (x > upper_crit), color='green', alpha=0.3, label='Type II Error')\n",
        "    plt.fill_between(x, y0, where=(x < lower_crit) | (x > upper_crit), color='red', alpha=0.2, label='Type I Error')\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.title(\"Type I and II Errors\")\n",
        "    plt.show()\n",
        "\n",
        "plot_type_errors(mu0=100, mu1=105, sigma=15, n=30)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "6. Independent T-test\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "group1 = np.random.normal(50, 5, 30)\n",
        "group2 = np.random.normal(53, 5, 30)\n",
        "t_stat, p_val = ttest_ind(group1, group2)\n",
        "print(f\"T = {t_stat:.3f}, P = {p_val:.3f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "7. Paired Sample T-test and Visualization\n",
        "\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "before = np.random.normal(70, 5, 30)\n",
        "after = before + np.random.normal(2, 3, 30)\n",
        "t_stat, p_val = ttest_rel(before, after)\n",
        "\n",
        "plt.plot(before, label=\"Before\")\n",
        "plt.plot(after, label=\"After\")\n",
        "plt.title(\"Paired T-test Data\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(f\"T = {t_stat:.3f}, P = {p_val:.3f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "8. Compare Z-test and T-test\n",
        "\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "data = np.random.normal(100, 15, 25)\n",
        "z_stat, z_p = z_test(data, pop_mean=95, pop_std=15)\n",
        "t_stat, t_p = ttest_1samp(data, popmean=95)\n",
        "\n",
        "print(f\"Z-test P = {z_p:.3f}, T-test P = {t_p:.3f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "9. Confidence Interval Function\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)\n",
        "    ci = stats.t.interval(confidence, len(data)-1, loc=mean, scale=sem)\n",
        "    print(f\"{confidence*100:.1f}% CI: {ci}\")\n",
        "    return ci\n",
        "\n",
        "sample = np.random.normal(55, 10, 40)\n",
        "confidence_interval(sample)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "10. Margin of Error Calculation\n",
        "\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    sem = stats.sem(data)\n",
        "    moe = sem * stats.t.ppf((1 + confidence) / 2, df=len(data)-1)\n",
        "    print(f\"Margin of Error: {moe:.2f}\")\n",
        "    return moe\n",
        "\n",
        "margin_of_error(sample)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "11. Bayesian Inference Example\n",
        "\n",
        "def bayes_theorem(prior_A, prob_B_given_A, prob_B_given_notA):\n",
        "    prob_notA = 1 - prior_A\n",
        "    prob_B = prob_B_given_A * prior_A + prob_B_given_notA * prob_notA\n",
        "    posterior_A = (prob_B_given_A * prior_A) / prob_B\n",
        "    print(f\"Posterior P(A|B): {posterior_A:.4f}\")\n",
        "    return posterior_A\n",
        "\n",
        "bayes_theorem(0.01, 0.9, 0.05)  # e.g., disease testing\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "12. Chi-square Test for Independence\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "data = [[30, 10], [20, 40]]\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "print(f\"Chi2 = {chi2:.2f}, P = {p:.3f}\")\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "13. Expected Frequencies for Chi-square\n",
        "\n",
        "observed = np.array([[30, 10], [20, 40]])\n",
        "_, _, _, expected = chi2_contingency(observed)\n",
        "print(\"Expected Frequencies:\\n\", expected)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "14. Goodness-of-Fit Test\n",
        "\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "observed = [20, 30, 50]\n",
        "expected = [25, 25, 50]\n",
        "chi2, p = chisquare(f_obs=observed, f_exp=expected)\n",
        "print(f\"Chi2 = {chi2:.2f}, P = {p:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MtScd4Q8hRW0"
      }
    }
  ]
}